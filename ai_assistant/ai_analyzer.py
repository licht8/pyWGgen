#!/usr/bin/env python3
"""AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ VPN."""

import json
import os
import sys
from typing import Dict, Any

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import settings

from .utils import run_cmd, check_ollama


def prepare_prompt(data: Dict[str, Any]) -> str:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞."""
    
    nat = data.get("nat", {})
    fw = data.get("firewalld", {})
    wg_status = data.get("wg_status", {})
    
    # –°–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤
    wg_interfaces = []
    for iface, info in wg_status.items():
        status = "–∞–∫—Ç–∏–≤–µ–Ω" if info.get("service_active") else "–Ω–µ–∞–∫—Ç–∏–≤–µ–Ω"
        wg_interfaces.append(f"{iface} ({status})")
    
    prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ WireGuard VPN. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.

–°–û–°–¢–û–Ø–ù–ò–ï –°–ò–°–¢–ï–ú–´:
- –°–µ—Ä–≤–µ—Ä: {data.get('hostname')}
- WireGuard –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã: {', '.join(wg_interfaces)}
- Firewalld: {fw.get('active')}
- WG –ø–æ—Ä—Ç –æ—Ç–∫—Ä—ã—Ç: {'–î–∞' if fw.get('wg_port_open') else '–ù–µ—Ç'}
- NAT: {'OK' if nat.get('ok') else '–ü–†–û–ë–õ–ï–ú–ê'}
- NAT –ø—Ä–∏—á–∏–Ω–∞: {nat.get('reason')}
- IP Forwarding: {'–í–∫–ª—é—á—ë–Ω' if nat.get('ip_forward') else '–í—ã–∫–ª—é—á–µ–Ω'}
- Peers –∞–∫—Ç–∏–≤–Ω—ã—Ö: {data.get('peers_active', 0)}
- Peers –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ: {data.get('peers_configured', 0)}
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∫–æ–Ω—Ñ–∏–≥–æ–≤: {data.get('user_peer_files', {}).get('total', 0)}

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
üü¢ –°—Ç–∞—Ç—É—Å: [OK/WARNING/ERROR] | –û—Ü–µ–Ω–∫–∞: [0-100]/100

üìù [–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö]

‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç:
‚Ä¢ [–ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ]
‚Ä¢ [–ß—Ç–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ]

{'‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã:' if not nat.get('ok') or data.get('wg_active', 0) < data.get('wg_total', 0) else '‚ú® –í—Å—ë –≤ –ø–æ—Ä—è–¥–∫–µ! –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.'}

–î–∞–π –∞–Ω–∞–ª–∏–∑:"""
    
    return prompt


def analyze_with_ai(data: Dict[str, Any]) -> str:
    """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é AI."""
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
    prompt = prepare_prompt(data)
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è curl
    json_data = {
        "model": settings.MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": settings.AI_TEMPERATURE
        }
    }
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è curl
    import tempfile
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        json.dump(json_data, f)
        temp_file = f.name
    
    try:
        # Curl –∫–æ–º–∞–Ω–¥–∞
        cmd = f"curl -s -X POST {settings.OLLAMA_HOST}/api/generate -d @{temp_file}"
        
        print("üîÑ –ó–∞–ø—Ä–æ—Å –∫ AI...")
        result = run_cmd(cmd, timeout=settings.AI_TIMEOUT)
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        os.unlink(temp_file)
        
        if not result or result.startswith("Error"):
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {result}")
            return "–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ AI"
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
        try:
            response = json.loads(result)
            ai_response = response.get('response', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞')
            
            print(ai_response)
            print("=" * 72)
            return ai_response
        
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç: {result[:200]}...")
            return "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞"
    
    except Exception as e:
        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        if os.path.exists(temp_file):
            os.unlink(temp_file)
        
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"


def interactive_question(data: Dict[str, Any], question: str) -> str:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤–æ–ø—Ä–æ—Å –∫ AI."""
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    context = f"""–ö–û–ù–¢–ï–ö–°–¢ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò:
- WireGuard: {data.get('wg_active')}/{data.get('wg_total')} –∞–∫—Ç–∏–≤–Ω—ã
- NAT: {'OK' if data.get('nat', {}).get('ok') else '–ü–†–û–ë–õ–ï–ú–ê'}
- Firewalld: {data.get('firewalld', {}).get('active')}
- Peers: {data.get('peers_active', 0)} –∞–∫—Ç–∏–≤–Ω—ã—Ö, {data.get('peers_configured', 0)} –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{question}

–û–¢–í–ï–¢ (–∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É):"""
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
    json_data = {
        "model": settings.MODEL_NAME,
        "prompt": context,
        "stream": False,
        "options": {
            "temperature": settings.CHAT_TEMPERATURE
        }
    }
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    import tempfile
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        json.dump(json_data, f)
        temp_file = f.name
    
    try:
        cmd = f"curl -s -X POST {settings.OLLAMA_HOST}/api/generate -d @{temp_file}"
        result = run_cmd(cmd, timeout=settings.CHAT_TIMEOUT)
        
        os.unlink(temp_file)
        
        if result and not result.startswith("Error"):
            try:
                response = json.loads(result)
                return response.get('response', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞')
            except json.JSONDecodeError:
                return "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞"
        
        return "–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"
    
    except Exception as e:
        if os.path.exists(temp_file):
            os.unlink(temp_file)
        return f"–û—à–∏–±–∫–∞: {str(e)}"
