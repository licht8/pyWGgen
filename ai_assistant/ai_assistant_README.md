<<<<<<< HEAD
# **AI Assistant Directory**  

This directory contains all necessary data, configurations, and scripts for the AI assistant. The assistant is designed for server status analysis, working with WireGuard, processing input data, and generating outputs using an LLM model.  

## **Directory Structure**  

### **1. `/ai_assistant/inputs/`**  
**Description**: Storage for input data used in analysis.  
- **`inputs.md`**: Documentation on the format and purpose of input data.  
- **Example files**:  
  - `wg_status.json`: Results of the `wg show` command.  
  - `wg0_config.json`: Parsed file from `/etc/wireguard/wg0.conf`.  
  - `params_config.json`: Parsed file from `/etc/wireguard/params`.  

---

### **2. `/ai_assistant/prompts/`**  
**Description**: Prompt templates for interacting with the LLM model.  
- **`prompts.md`**: Documentation on the format and purpose of prompts.  
- **Example files**:  
  - `default_prompt.txt`: Basic prompt for system status analysis.  
  - `analysis_prompt.txt`: Specialized prompt for WireGuard analysis.  

---

### **3. `/ai_assistant/models/`**  
**Description**: Configuration, examples, and auxiliary data for the LLM model.  
- **`models.md`**: Documentation on model configuration and setup.  
- **Example files**:  
  - `config.json`: LLM connection settings (API address, model, parameters).  
  - `examples/`: Sample input data and how the model processes it.  

---

### **4. `/ai_assistant/outputs/`**  
**Description**: Assistant's output results.  
- **`outputs.md`**: Documentation on output data structure.  
- **Example files**:  
  - `insights.json`: Analytical data generated by the model.  
  - `logs/`: Directory containing logs:  
    - `error.log`: Error logs.  
    - `activity.log`: Activity logs.  

---

### **5. `/ai_assistant/scripts/`**  
**Description**: Auxiliary scripts for data processing and interaction with the LLM.  
- **`scripts.md`**: Documentation on script usage.  
- **Example files**:  
  - `preprocess.py`: Script for preprocessing input data.  
  - `query_model.py`: Script for interacting with the LLM.  

---

### **6. `/ai_assistant/chats/`**  
**Description**: History of chats between the assistant and the administrator.  
- **`chats.md`**: Documentation on chat storage and structure.  
- **Example files**:  
  - `chat_2024-12-21.json`: Chat log with the administrator for a specific date.  

---

## **Usage**  

1. **Data Collection**:  
   - Place input data in the `/inputs/` directory in JSON or text file format.  

2. **Prompt Templates**:  
   - Edit or add new prompts in `/prompts/` to configure interaction with the LLM.  

3. **Running Analysis**:  
   - Use scripts from `/scripts/` to process data and send requests to the model.  

4. **Results**:  
   - The assistantâ€™s outputs and logs will be stored in `/outputs/`.  

5. **Chats**:  
   - The assistant's interaction history with the administrator is saved in `/chats/`.  

---

## **Notes**  
- Ensure the assistant has access to all required data and configuration files for proper operation.  
- All model interaction settings are located in `/models/config.json`.  
=======
# AI Assistant Directory

This repository contains all necessary data, configurations, and scripts for the AI assistant. The assistant is designed for server status analysis, working with WireGuard, processing input data, and generating outputs using an LLM model.

## ðŸ“ Directory Structure

### 1. `/ai_assistant/inputs/`
**Description:** Storage for input data used in analysis.

- **`inputs.md`** â€“ Documentation on the format and purpose of input data.
- **Example files:**
  - `wg_status.json` â€“ Results of the `wg show` command.
  - `wg0_config.json` â€“ Parsed file from `/etc/wireguard/wg0.conf`.
  - `params_config.json` â€“ Parsed file from `/etc/wireguard/params`.

### 2. `/ai_assistant/prompts/`
**Description:** Templates for prompts used to interact with the LLM model.

- **`prompts.md`** â€“ Documentation on the format and purpose of prompts.
- **Example files:**
  - `default_prompt.txt` â€“ Basic prompt for system status analysis.
  - `analysis_prompt.txt` â€“ Specialized prompt for WireGuard analysis.

### 3. `/ai_assistant/models/`
**Description:** Configuration, examples, and auxiliary data for the LLM model.

- **`models.md`** â€“ Documentation on model configuration and setup.
- **Example files:**
  - `config.json` â€“ Settings for connecting to the LLM (API address, model, parameters).
  - `examples/` â€“ Sample input data and how the model processes them.

### 4. `/ai_assistant/outputs/`
**Description:** Assistant's output results.

- **`outputs.md`** â€“ Documentation on output data structure.
- **Example files:**
  - `insights.json` â€“ Analytical data generated by the model.
  - `logs/` â€“ Directory containing logs:
    - `error.log` â€“ Error logs.
    - `activity.log` â€“ Activity logs.

### 5. `/ai_assistant/scripts/`
**Description:** Auxiliary scripts for data processing and interaction with the LLM.

- **`scripts.md`** â€“ Documentation on script usage.
- **Example files:**
  - `preprocess.py` â€“ Script for preprocessing input data.
  - `query_model.py` â€“ Script for interacting with the LLM.

### 6. `/ai_assistant/chats/`
**Description:** History of chats between the assistant and the administrator.

- **`chats.md`** â€“ Documentation on chat storage and structure.
- **Example files:**
  - `chat_2024-12-21.json` â€“ Chat log with the administrator for a specific date.

---

## ðŸš€ Usage

### 1ï¸âƒ£ Data Collection
Place input data in the `/inputs/` directory in JSON or text file format.

### 2ï¸âƒ£ Prompt Templates
Edit or add new prompts in `/prompts/` to customize LLM interaction.

### 3ï¸âƒ£ Running Analysis
Use scripts from `/scripts/` to process data and send requests to the model.

### 4ï¸âƒ£ Results
The assistantâ€™s outputs and logs will be stored in `/outputs/`.

### 5ï¸âƒ£ Chats
Interaction history between the assistant and the administrator is saved in `/chats/`.

---

## âš ï¸ Notes

- Ensure the assistant has access to all required data and configuration files for proper operation.
- All settings related to model interaction are located in `/models/config.json`.

---

## ðŸ“œ License
This project is licensed under the MIT License â€“ see the [LICENSE](LICENSE) file for details.

## ðŸ“¬ Contact
For any issues or contributions, feel free to open an issue or submit a pull request!
>>>>>>> 2f27ea6587ad55e259b4c230e250a53875218acc
